import sys
import socket
import numpy as np
import cv2
from collections import Counter
from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QVBoxLayout, QWidget, QPushButton, QHBoxLayout, QTextEdit
from PyQt5.QtCore import Qt, QThread, pyqtSignal
from PyQt5.QtGui import QImage, QPixmap, QFont
from PyQt5.QtCore import QTimer
from ultralytics import YOLO
from catalog import catalog
import pyttsx3
import threading
from openai import OpenAI

# ----------------- è¯­éŸ³çº¿ç¨‹ç±» -----------------
# ----------------- å…¨å±€è¯­éŸ³åˆå§‹åŒ– -----------------
engine = pyttsx3.init()
engine.setProperty('rate', 170)
engine.setProperty('volume', 1.0)
for voice in engine.getProperty('voices'):
    if "zh" in voice.id or "chinese" in voice.name.lower():
        engine.setProperty('voice', voice.id)
        break

speech_lock = threading.Lock()

class SpeechWorker(QThread):
    def __init__(self, text):
        super().__init__()
        self.text = text

    def run(self):
        with speech_lock:
            engine.say(self.text)
            engine.runAndWait()

# ----------------- å›¾åƒæ¥æ”¶çº¿ç¨‹ -----------------
IMG_W, IMG_H = 1280, 720
BYTES_PER_LINE = 2 + IMG_W * 2
HOST, PORT = "192.168.0.3", 6102
SORT_LINES = True

class FrameListener(QThread):
    frame_ready = pyqtSignal(np.ndarray)

    def __init__(self):
        super().__init__()
        self._active = False
        self._socket = None

    def stop(self):
        self._active = False
        if self._socket:
            try:
                self._socket.close()
            except:
                pass
            self._socket = None

    def run(self):
        self._active = True
        self._socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 2**20)
        self._socket.bind((HOST, PORT))
        self._socket.settimeout(0.1)

        lines = {}

        while self._active:
            try:
                data, _ = self._socket.recvfrom(4096)
                if len(data) != BYTES_PER_LINE:
                    continue

                idx = int.from_bytes(data[:2], 'little')
                if 0 <= idx < IMG_H:
                    lines[idx] = data[2:]

                if len(lines) == IMG_H:
                    try:
                        full = b''.join(lines[i] for i in sorted(lines)) if SORT_LINES else b''.join(lines[i] for i in range(IMG_H))
                        pixels = np.frombuffer(full, dtype=np.uint16)
                        r = ((pixels >> 11) & 0x1F) << 3
                        g = ((pixels >> 5) & 0x3F) << 2
                        b = (pixels & 0x1F) << 3
                        img = np.stack((r, g, b), axis=-1).astype(np.uint8).reshape((IMG_H, IMG_W, 3))
                        self.frame_ready.emit(img.copy())
                    except:
                        pass
                    finally:
                        lines.clear()
            except:
                continue

class DetectionWorker(QThread):
    processed = pyqtSignal(np.ndarray, np.ndarray)

    def __init__(self, model):
        super().__init__()
        self.model = model
        self._queue = []
        self._active = True

    def stop(self):
        self._active = False
        self.wait()

    def add(self, frame):
        if len(self._queue) < 2:
            self._queue.append(frame)

    def run(self):
        while self._active:
            if self._queue:
                frame = self._queue.pop(0)
                img_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                result = self.model(img_bgr)[0]
                visual = cv2.cvtColor(result.plot(), cv2.COLOR_BGR2RGB)
                self.processed.emit(frame, visual)
            else:
                self.msleep(5)

# ---------------- API client -------------------
client = OpenAI(api_key="sk-91409a846ef6407d95b1dfa46fa24234", base_url="https://api.deepseek.com")

class SuggestionWorker(QThread):
    result_ready = pyqtSignal(str)

    def __init__(self, summary_text):
        super().__init__()
        self.summary_text = summary_text

    def run(self):
        try:
            prompt = f"ç”¨æˆ·åˆšåˆšè´­ä¹°äº†ä»¥ä¸‹å•†å“ï¼š{self.summary_text}è¯·ä½ ç”¨ä¸€å¥è¯ç»™ç”¨æˆ·ä¸€äº›å»ºè®®æˆ–è€…è¯„ä»·ï¼Œè¦æ±‚å£è¯­åŒ–ï¼Œåˆ†éš”ç®€çŸ­æœ‰è¶£ï¼Œå›å¤å’ŒçœŸäººèŠå¤©ä¸€æ ·ï¼Œä¸è¦åŠ è¡¨æƒ…ã€‚"
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            suggestion = response.choices[0].message.content.strip()
        except Exception as e:
            suggestion = f"å»ºè®®è·å–å¤±è´¥ï¼š{e}"
        self.result_ready.emit(suggestion)

class VisualApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("æ™ºæ„Ÿäº¤äº’å¼é›¶å”®èˆ±")
        self.resize(1400, 1000)
        self.setStyleSheet("background-color: #e8f0fe;")

        self._model = YOLO("yolov8s.pt")
        self._detector = DetectionWorker(self._model)
        self._detector.processed.connect(self.update_view)
        self._detector.start()

        self._receiver = FrameListener()
        self._receiver.frame_ready.connect(self.enqueue_image)
        self._receiver.start()

        self._latest = []
        self._opened = []
        self._closed = []

        self._init_ui()

    def _init_ui(self):
        self._label = QLabel("æ£€æµ‹å›¾åƒæ˜¾ç¤ºåŒºåŸŸ")
        self._label.setAlignment(Qt.AlignCenter)
        self._label.setFixedSize(IMG_W, IMG_H)
        self._label.setStyleSheet("border: 2px solid #333; background-color: white;")

        self._info = QTextEdit()
        self._info.setReadOnly(True)
        self._info.setFixedHeight(200)
        self._info.setStyleSheet("background-color: #ffffff; font-size: 24px; padding: 16px;")

        btn_open = QPushButton("ğŸŸ¢ å¼€æŸœ")
        btn_close = QPushButton("ğŸ”´ å…³æŸœ")

        for b in (btn_open, btn_close):
            b.setFixedSize(150, 55)
            b.setStyleSheet("font-size: 20px; font-weight: bold; border-radius: 10px;")

        btn_open.clicked.connect(self.handle_open)
        btn_close.clicked.connect(self.handle_close)

        btn_box = QHBoxLayout()
        btn_box.addWidget(btn_open)
        btn_box.addWidget(btn_close)
        btn_box.setSpacing(40)

        # é¡¶éƒ¨ logo å’Œæ ‡é¢˜
        logo_left = QLabel()
        logo_left.setPixmap(QPixmap("logo.png").scaled(400, 400, Qt.KeepAspectRatio, Qt.SmoothTransformation))
        logo_left.setAlignment(Qt.AlignLeft | Qt.AlignTop)

        logo_right = QLabel()
        logo_right.setPixmap(QPixmap("logo2.png").scaled(400, 400, Qt.KeepAspectRatio, Qt.SmoothTransformation))
        logo_right.setAlignment(Qt.AlignRight | Qt.AlignTop)

        # é¡¶éƒ¨åŒºåŸŸï¼šå·¦ä¸Šè§’ logo + ä¸­é—´æ ‡é¢˜
        top_bar = QHBoxLayout()
        top_bar.addWidget(logo_left, alignment=Qt.AlignLeft)
        top_bar.addStretch()
        top_bar.addWidget(logo_right, alignment=Qt.AlignRight)

        title = QLabel("æ ¡å›­è‡ªåŠ¨å”®è´§æŸœ")
        title.setFont(QFont("Arial", 32, QFont.Bold))
        title.setAlignment(Qt.AlignCenter)
        title.setStyleSheet("color: #2a4d69; margin-top: 10px;")

        # æ€»ä½“å¸ƒå±€
        layout = QVBoxLayout()
        layout.addLayout(top_bar)
        layout.addWidget(title, alignment=Qt.AlignCenter)
        layout.addWidget(self._label, alignment=Qt.AlignCenter)
        layout.addLayout(btn_box)
        layout.addWidget(self._info)

        wrapper = QWidget()
        wrapper.setLayout(layout)
        self.setCentralWidget(wrapper)

    def enqueue_image(self, image):
        self._detector.add(image)

    def update_view(self, raw, annotated):
        qimg = QImage(annotated.data, annotated.shape[1], annotated.shape[0], annotated.shape[1]*3, QImage.Format_RGB888)
        self._label.setPixmap(QPixmap.fromImage(qimg))
        self._latest = self._extract_labels(raw)

    def _extract_labels(self, frame):
        bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        results = self._model(bgr)[0]
        return [self._model.names[int(c)] for c in results.boxes.cls]

    def handle_open(self):
        self._info.setHtml('<span style="font-size:28px;">æŸœé—¨å·²æ‰“å¼€ï¼Œè¯·å–èµ°å•†å“...</span>')
        self._speak("æŸœé—¨å·²æ‰“å¼€ï¼Œè¯·å–èµ°å•†å“")
        self._opened = self._latest.copy()

    def handle_close(self):
        self._closed = self._latest.copy()
        self._summarize()
        # ğŸ” å»¶è¿Ÿ500msè°ƒç”¨å»ºè®®ï¼Œç¡®ä¿è¯­éŸ³å’Œæ£€æµ‹å¤„ç†å®Œæ¯•
        QTimer.singleShot(100, self._start_suggestion)

    def _summarize(self):
        purchased = Counter(self._opened) - Counter(self._closed)

        total = 0
        output = ["ğŸ›’ è´­ç‰©æ¸…å•ï¼š"]
        speak_text = "æ‚¨è´­ä¹°äº†ï¼š"

        for item, count in purchased.items():
            if item in catalog:
                label = catalog[item]["name"]
                price = catalog[item]["price"]
                output.append(f"{label} x{count} - Â¥{price * count}")
                speak_text += f"{label} {count}ä»¶ï¼Œ"
                total += price * count
            else:
                output.append(f"{item} x{count} - æœªçŸ¥ä»·æ ¼")
                speak_text += f"{item} {count}ä»¶ï¼Œ"

        if total == 0:
            output = ["ğŸ›’ æ‚¨æœ¬æ¬¡è´­ä¹°å…±è®¡ 0 å…ƒ", "æ¬¢è¿ä¸‹æ¬¡å…‰ä¸´ï¼"]
            self._info.setPlainText("\n".join(output))
            self._speak("æ¬¢è¿ä¸‹æ¬¡å…‰ä¸´")
        else:
            output.append(f"\nğŸ’° éœ€è¦æ”¯ä»˜: Â¥{total}")
            speak_text += f"å…±è®¡ {total} å…ƒ"
            self._info.setPlainText("\n".join(output))
            self._speak(speak_text)

    def closeEvent(self, event):
        if self._detector:
            self._detector.stop()
        if self._receiver:
            self._receiver.stop()
        event.accept()

    def _speak(self, text):
        self._speech_thread = SpeechWorker(text)
        self._speech_thread.start()

    def display_suggestion(self, suggestion):
        self._info.append(f"\nğŸ’¡ æ™ºèƒ½å»ºè®®ï¼š{suggestion}")
        self._speak(f"\n {suggestion}")

        # â€”â€” æ–°å¢ï¼šå†å»¶è¿Ÿ 200ms è§¦å‘è¡¥è´§æé†’ â€”â€” #
        QTimer.singleShot(200, self._restock_reminder)
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” #

    def _start_suggestion(self):
        # æ„å»ºè´­ä¹°æ‘˜è¦
        purchased = Counter(self._opened) - Counter(self._closed)
        purchase_summary = ""
        for item, count in purchased.items():
            if item in catalog:
                label = catalog[item]["name"]
                purchase_summary += f"{label} {count}ä»¶ï¼Œ"
            else:
                purchase_summary += f"{item} {count}ä»¶ï¼Œ"

        if purchase_summary.strip():  # æœ‰è´­ä¹°è®°å½•æ‰å‘é€
            self._suggest_thread = SuggestionWorker(purchase_summary)
            self._suggest_thread.result_ready.connect(self.display_suggestion)
            self._suggest_thread.start()
        else:
            # â€”â€” æ–°å¢ï¼šå†å»¶è¿Ÿ 200ms è§¦å‘è¡¥è´§æé†’ â€”â€” #
            QTimer.singleShot(200, self._restock_reminder)
            # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” #

    def _restock_reminder(self):
        total_labels = len(self._closed)
        if total_labels == 0:
            msg = "âš ï¸ æŸœå†…å•†å“å·²å…¨éƒ¨å”®ç½„ï¼Œè¯·åŠæ—¶è¡¥è´§ï¼"
            msg_1 = "æŸœå†…å•†å“å·²å…¨éƒ¨å”®ç½„ï¼Œè¯·åŠæ—¶è¡¥è´§ï¼"
            # æ—¢å¯ä»¥ç”¨ setPlainTextï¼ˆè¦†ç›–ï¼‰ï¼Œä¹Ÿå¯ä»¥ appendï¼ˆæ¥åœ¨åé¢ï¼‰ï¼š
            self._info.append(f"\n{msg}")
            self._speak(msg_1)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = VisualApp()
    window.show()
    sys.exit(app.exec_())